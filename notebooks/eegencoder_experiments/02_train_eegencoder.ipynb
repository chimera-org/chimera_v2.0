{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNWACOxs4Ydu4uafiwssjr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chimera-org/chimera_v2.0/blob/main/notebooks/eegencoder_experiments/02_train_eegencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone your GitHub repository\n",
        "!git clone https://github.com/chimera-org/chimera_v2.0/\n",
        "\n",
        "print(\"‚úÖ Repository cloned.\")"
      ],
      "metadata": {
        "id": "gT4AzxOWji5A",
        "outputId": "04a4f918-2e17-4777-8704-540043f0ce1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'chimera_v2.0'...\n",
            "remote: Enumerating objects: 1666, done.\u001b[K\n",
            "remote: Counting objects: 100% (211/211), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 1666 (delta 160), reused 105 (delta 105), pack-reused 1455 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1666/1666), 958.79 KiB | 8.72 MiB/s, done.\n",
            "Resolving deltas: 100% (846/846), done.\n",
            "‚úÖ Repository cloned.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup Environment for EEGEncoder Training\n",
        "\n",
        "# 1. Install dependencies\n",
        "!pip install torch torchvision tqdm scikit-learn matplotlib mne numpy scipy --quiet\n",
        "\n",
        "# 2. Add src to Python path\n",
        "import sys\n",
        "import os\n",
        "\n",
        "SRC_PATH = \"/content/chimera_v2.0/src\"\n",
        "if SRC_PATH not in sys.path:\n",
        "    sys.path.append(SRC_PATH)\n",
        "\n",
        "# 3. Verify path\n",
        "assert os.path.exists(SRC_PATH), f\"Path not found: {SRC_PATH}\"\n",
        "\n",
        "# 4. Import modules\n",
        "import torch\n",
        "from eegencoder.model import EEGEncoder\n",
        "from eegencoder.train import train_model, get_loso_dataloaders, run_loso_cross_validation\n",
        "from eegencoder.data_loader import BCIC4_2A_Loader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 5. Verify setup\n",
        "print(\"‚úÖ Environment ready\")\n",
        "print(f\"üì¶ PyTorch {torch.__version__}\")\n",
        "print(f\"üî• CUDA: {torch.cuda.is_available()}\")\n",
        "print(f\"üìÅ Path: {SRC_PATH}\")"
      ],
      "metadata": {
        "id": "sewHFEfjwU9T",
        "outputId": "b662b346-f6ff-45c5-948d-4c0d909c2f2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úÖ Environment ready\n",
            "üì¶ PyTorch 2.9.0+cu126\n",
            "üî• CUDA: False\n",
            "üìÅ Path: /content/chimera_v2.0/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3: Quick Single Subject Test\n",
        "# ==================================\n",
        "\"\"\"\n",
        "Before full LOSO, train on one subject to verify everything works\n",
        "\"\"\"\n",
        "\n",
        "# Data paths\n",
        "DATA_DIR = \"/content/drive/MyDrive/chimera_v2.0/data/bcic4_2a_processed/\"\n",
        "MODEL_SAVE_DIR = \"/content/drive/MyDrive/chimera_v2.0/models/\"\n",
        "\n",
        "# Test subject 1 (quick 5 epoch test)\n",
        "train_loader, test_loader = get_loso_dataloaders(\n",
        "    DATA_DIR, test_subject=1, batch_size=32\n",
        ")\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)} | Test batches: {len(test_loader)}\")\n",
        "\n",
        "# Create model\n",
        "model = EEGEncoder(num_classes=4, pi_compatibility=False)\n",
        "model = model.to(device)\n",
        "\n",
        "# Quick training\n",
        "trained_model, history = train_model(\n",
        "    model, train_loader, test_loader, device,\n",
        "    epochs=5, lr=1e-3, test_subject=1, save_dir=MODEL_SAVE_DIR\n",
        ")\n",
        "\n",
        "# Plot training curve\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot([h['accuracy'] for h in history['train']], label='Train')\n",
        "plt.plot([h['accuracy'] for h in history['val']], label='Val')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot([h['loss'] for h in history['train']], label='Train')\n",
        "plt.plot([h['loss'] for h in history['val']], label='Val')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "abMPJoyrzxv7",
        "outputId": "d8a76384-d904-4d75-ce7e-6c320ac3845b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "need at least one array to concatenate",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1266439846.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Test subject 1 (quick 5 epoch test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m train_loader, test_loader = get_loso_dataloaders(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_subject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m )\n",
            "\u001b[0;32m/content/chimera_v2.0/src/eegencoder/train.py\u001b[0m in \u001b[0;36mget_loso_dataloaders\u001b[0;34m(data_dir, test_subject, batch_size, num_workers)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0my_train_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL: Verify Preprocessed Data Exists\n",
        "# ======================================\n",
        "DATA_DIR = \"/content/drive/MyDrive/chimera_v2.0/data/bcic4_2a_processed/\"\n",
        "\n",
        "import os\n",
        "\n",
        "print(f\"Checking: {DATA_DIR}\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    print(f\"‚ùå Directory does NOT exist: {DATA_DIR}\")\n",
        "else:\n",
        "    files = os.listdir(DATA_DIR)\n",
        "    npy_files = [f for f in files if f.endswith('.npy')]\n",
        "    print(f\"‚úÖ Found {len(npy_files)} .npy files\")\n",
        "\n",
        "    # Show first few\n",
        "    print(\"\\nFirst 10 files:\")\n",
        "    for f in sorted(npy_files)[:10]:\n",
        "        print(f\"  - {f}\")\n",
        "\n",
        "    # Check if we have both X and y for subject 01\n",
        "    x_files = [f for f in npy_files if 'X.npy' in f]\n",
        "    y_files = [f for f in npy_files if 'y.npy' in f]\n",
        "    print(f\"\\nX files: {len(x_files)}, Y files: {len(y_files)}\")\n",
        "\n",
        "# If empty, you need to run the preprocessing cell (Cell 6) in 01_load_bcic4_2a.ipynb"
      ],
      "metadata": {
        "id": "qL9WVAEq07Se",
        "outputId": "c841b50e-8379-4ade-ccd5-511b9e5aac6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking: /content/drive/MyDrive/chimera_v2.0/data/bcic4_2a_processed/\n",
            "==================================================\n",
            "‚ùå Directory does NOT exist: /content/drive/MyDrive/chimera_v2.0/data/bcic4_2a_processed/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TI-wgXKWWIwG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}